{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import math   # for mathematical operations\n",
    "import random\n",
    "from glob import glob\n",
    "import cv2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 2\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "width, height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER_PATH = r'C:\\\\Users\\djcoo\\Documents\\LYIT\\Final\\project\\RWF-2000_test\\train'\n",
    "TEST_FOLDER_PATH = r'C:\\\\Users\\djcoo\\Documents\\LYIT\\Final\\project\\RWF-2000_test\\val'\n",
    "\n",
    "def listDir(dir):\n",
    "    catgeory = {}\n",
    "    dirNames = os.listdir(dir)\n",
    "    for dirName in dirNames:\n",
    "        catgeory[dirName] = []\n",
    "#         print('Directory Name : '+ dirName)\n",
    "        dir_path = os.path.abspath(os.path.join(dir, dirName))\n",
    "#         print('Directory Path : '+ dir_path)\n",
    "        fileNames = os.listdir(dir_path)\n",
    "        for fileName in fileNames:\n",
    "            file_path = os.path.abspath(os.path.join(dir_path, fileName))\n",
    "#             print('File Path : '+ file_path )\n",
    "            catgeory[dirName].append(file_path)\n",
    "    return catgeory\n",
    "\n",
    "LIST_OF_TRAIN_CATEGORY = listDir(TRAIN_FOLDER_PATH)\n",
    "LIST_OF_TEST_CATEGORY = listDir(TEST_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(path_arr, flag):\n",
    "    label_arr = [\"Fight\", \"NonFight\"]\n",
    "    for label in label_arr:\n",
    "        image_count = 0\n",
    "        for video_path in tqdm(path_arr[label]):\n",
    "#             video_name = video_path.split('\\\\').pop().split(\".\")[0]\n",
    "        #     print(video_name)\n",
    "            cap = cv2.VideoCapture(video_path)   # capturing the video from the given path\n",
    "            frameRate = cap.get(5) #frame rate\n",
    "            frame_count = 0\n",
    "            while(cap.isOpened()):\n",
    "                frameId = cap.get(1) #current frame number\n",
    "                ret, frame = cap.read()\n",
    "                if (ret != True):\n",
    "                    break\n",
    "                if (frameId % math.floor(frameRate) == 0):\n",
    "                    # storing the frames in a new folder named train_1\n",
    "                    TRAIN_FRAME_PATH = \"C:\\\\Users\\\\djcoo\\\\Documents\\\\LYIT\\\\Final\\\\project\\\\frames\\\\\"+ flag +\"\\\\\" + label + \"_\"\n",
    "#                     filename = r\"%s\" %TRAIN_FRAME_PATH + video_name +\"_frame%d.jpg\" %frame_count;\n",
    "                    filename = r\"%s\" %TRAIN_FRAME_PATH + \"%d\"%image_count +\"_frame%d.jpg\" %frame_count\n",
    "#                     print(filename)\n",
    "                    frame_count+=1\n",
    "                    cv2.imwrite(filename, frame)\n",
    "            image_count+=1\n",
    "            cap.release()\n",
    "\n",
    "get_video_frames(LIST_OF_TRAIN_CATEGORY, \"train\")\n",
    "get_video_frames(LIST_OF_TEST_CATEGORY, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(r\"C:\\\\Users\\\\djcoo\\\\Documents\\\\LYIT\\\\Final\\\\project\\\\frames\\\\train\\\\*.jpg\")\n",
    "# creating an empty list\n",
    "random.shuffle(images)\n",
    "\n",
    "train_image = []\n",
    "train_class = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for img_path in tqdm(images):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "#     img = image.load_img(img_path, target_size=(224,224,3))\n",
    "#     # converting it to array\n",
    "#     img = image.img_to_array(img)\n",
    "#     # normalizing the pixel value\n",
    "#     img = img/255\n",
    "#     # appending the image to the train_image list\n",
    "#     print(img_path) \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    train_image.append(image)\n",
    "    train_class.append(img_path.split(\"\\\\\").pop().split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob(r\"C:\\\\Users\\\\djcoo\\\\Documents\\\\LYIT\\\\Final\\\\project\\\\frames\\\\test\\\\*.jpg\")\n",
    "# creating an empty list\n",
    "random.shuffle(images)\n",
    "\n",
    "test_image = []\n",
    "test_class = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for img_path in tqdm(images):\n",
    "#     # loading the image and keeping the target size as (224,224,3)\n",
    "#     img = image.load_img(img_path, target_size=(224,224,3))\n",
    "#     # converting it to array\n",
    "#     img = image.img_to_array(img)\n",
    "#     # normalizing the pixel value\n",
    "#     img = img/255\n",
    "    # appending the image to the train_image list\n",
    "#     print(img_path) \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    test_image.append(image)\n",
    "    test_class.append(img_path.split(\"\\\\\").pop().split(\"_\")[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# y_train = lb.fit_transform(train_class)\n",
    "# y_test = lb.fit_transform(test_class)\n",
    "\n",
    "# print(len(y_train))\n",
    "# print(len(y_test))\n",
    "\n",
    "# converting the list to numpy array\n",
    "X_train = np.array(train_image,'float32')\n",
    "X_test = np.array(test_image,'float32')\n",
    "#y_train = np.array(train_class,'float32')\n",
    "# y_test = np.array(test_class,'float32')\n",
    "y_train = to_categorical(lb.fit_transform(train_class))\n",
    "y_test = to_categorical(lb.fit_transform(test_class))\n",
    "print(y_test)\n",
    "\n",
    "# train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "# test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "# #cannot produce\n",
    "# #normalizing data between 0 and 1\n",
    "# X_train -= np.median(X_train, axis=0)\n",
    "# X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "# X_test -= np.median(X_test, axis=0)\n",
    "# X_test /= np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
