{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    " \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics as km\n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import math   # for mathematical operations\n",
    "import random\n",
    "from glob import glob\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height , img_width = 244, 244\n",
    "seq_len = 70\n",
    "IMAGE_CHANNELS = 3\n",
    "batch = 8\n",
    "\n",
    "INPUT_SHAPE = (seq_len, img_height, img_width, IMAGE_CHANNELS)\n",
    "\n",
    "classes = [\"Fight\", \"NonFight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER_PATH = r'C:\\\\Users\\djcoo\\Documents\\LYIT\\Final\\project\\RWF-2000_test\\train'\n",
    "TEST_FOLDER_PATH = r'C:\\\\Users\\djcoo\\Documents\\LYIT\\Final\\project\\RWF-2000_test\\val'\n",
    "\n",
    "def listDir(dir):\n",
    "    catgeory = {}\n",
    "    dirNames = os.listdir(dir)\n",
    "    for dirName in dirNames:\n",
    "        catgeory[dirName] = []\n",
    "#         print('Directory Name : '+ dirName)\n",
    "        dir_path = os.path.abspath(os.path.join(dir, dirName))\n",
    "#         print('Directory Path : '+ dir_path)\n",
    "        fileNames = os.listdir(dir_path)\n",
    "        for fileName in fileNames:\n",
    "            file_path = os.path.abspath(os.path.join(dir_path, fileName))\n",
    "#             print('File Path : '+ file_path )\n",
    "            catgeory[dirName].append(file_path)\n",
    "    return catgeory\n",
    "\n",
    "LIST_OF_TRAIN_CATEGORY = listDir(TRAIN_FOLDER_PATH)\n",
    "LIST_OF_TEST_CATEGORY = listDir(TEST_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_video_frames(path_arr, flag):\n",
    "    label_arr = [\"Fight\", \"NonFight\"]\n",
    "    for label in label_arr:\n",
    "        image_count = 0\n",
    "        for video_path in tqdm(path_arr[label]):\n",
    "#             video_name = video_path.split('\\\\').pop().split(\".\")[0]\n",
    "        #     print(video_name)\n",
    "            cap = cv2.VideoCapture(video_path)   # capturing the video from the given path\n",
    "            frameRate = cap.get(5) #frame rate\n",
    "            frame_count = 0\n",
    "            while(cap.isOpened()):\n",
    "                frameId = cap.get(1) #current frame number\n",
    "                ret, frame = cap.read()\n",
    "                if (ret != True):\n",
    "                    break\n",
    "                if (frameId % math.floor(frameRate) == 0):\n",
    "                    # storing the frames in a new folder named train_1\n",
    "                    TRAIN_FRAME_PATH = \"C:\\\\Users\\\\djcoo\\\\Documents\\\\LYIT\\\\Final\\\\project\\\\frames\\\\\"+ flag +\"\\\\\" + label + \"_\"\n",
    "#                     filename = r\"%s\" %TRAIN_FRAME_PATH + video_name +\"_frame%d.jpg\" %frame_count;\n",
    "                    filename = r\"%s\" %TRAIN_FRAME_PATH + \"%d\"%image_count +\"_frame%d.jpg\" %frame_count\n",
    "#                     print(filename)\n",
    "                    frame_count+=1\n",
    "                    cv2.imwrite(filename, frame)\n",
    "            image_count+=1\n",
    "            cap.release()\n",
    "\n",
    "get_video_frames(LIST_OF_TRAIN_CATEGORY, \"train\")\n",
    "get_video_frames(LIST_OF_TEST_CATEGORY, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 442.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob(r\"C:\\\\Users\\\\djcoo\\\\Documents\\\\LYIT\\\\Final\\\\project\\\\frames\\\\train\\\\*.jpg\")\n",
    "# creating an empty list\n",
    "random.shuffle(images)\n",
    "\n",
    "train_image = []\n",
    "train_class = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for img_path in tqdm(images):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "#     img = image.load_img(img_path, target_size=(224,224,3))\n",
    "#     # converting it to array\n",
    "#     img = image.img_to_array(img)\n",
    "#     # normalizing the pixel value\n",
    "#     img = img/255\n",
    "#     # appending the image to the train_image list\n",
    "#     print(img_path) \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    train_image.append(image)\n",
    "    train_class.append(img_path.split(\"\\\\\").pop().split(\"_\")[0])\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X_train = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 95/95 [00:00<00:00, 113.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob(r\"C:\\\\Users\\\\djcoo\\\\Documents\\\\LYIT\\\\Final\\\\project\\\\frames\\\\test\\\\*.jpg\")\n",
    "# creating an empty list\n",
    "random.shuffle(images)\n",
    "\n",
    "test_image = []\n",
    "test_class = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for img_path in tqdm(images):\n",
    "#     # loading the image and keeping the target size as (224,224,3)\n",
    "#     img = image.load_img(img_path, target_size=(224,224,3))\n",
    "#     # converting it to array\n",
    "#     img = image.img_to_array(img)\n",
    "#     # normalizing the pixel value\n",
    "#     img = img/255\n",
    "    # appending the image to the train_image list\n",
    "#     print(img_path) \n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    test_image.append(image)\n",
    "    test_class.append(img_path.split(\"\\\\\").pop().split(\"_\")[0])\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X_test = np.array(test_image)\n",
    "\n",
    "# shape of the array\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = to_categorical(lb.fit_transform(train_class))\n",
    "y_test = to_categorical(lb.fit_transform(test_class))\n",
    "\n",
    "# print(len(y_train))\n",
    "# print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 40, kernel_size = (3, 3), return_sequences = False, data_format = \"channels_last\", batch_input_shape = INPUT_SHAPE))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (8, 242, 242, 40)         62080     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (8, 242, 242, 40)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (8, 2342560)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (8, 512)                  1199391232\n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (8, 512)                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (8, 6)                    3078      \n",
      "=================================================================\n",
      "Total params: 1,199,456,390\n",
      "Trainable params: 1,199,456,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv_lst_m2d_2_input to have 5 dimensions, but got array with shape (150, 224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a83b0281c0c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv_lst_m2d_2_input to have 5 dimensions, but got array with shape (150, 224, 224, 3)"
     ]
    }
   ],
   "source": [
    "earlystop = EarlyStopping(patience=7)\n",
    "callbacks = [earlystop]\n",
    " \n",
    "history = model.fit(x = X_train, y = y_train, epochs=40 , shuffle=True, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    " \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
